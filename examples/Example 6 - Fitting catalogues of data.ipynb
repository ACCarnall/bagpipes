{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting catalogues of data with Bagpipes\n",
    "================================\n",
    "\n",
    "Commonly, we wish to fit a whole catalogue of observations of different objects (e.g. the Guo et al. (2013) [CANDELS GOODS South catalogue](https://archive.stsci.edu/prepds/candels) used in the previous examples). \n",
    "\n",
    "One approach would be to wrap the fitting commands from the previous three examples in a for loop, however Bagpipes provides a [catalogue fitting interface through the fit_catalogue class](https://bagpipes.readthedocs.io/en/latest/fitting_catalogues.html), which makes things easier. One advantage of doing catalogue fitting this way is the ability for different objects to automatically be parcelled out to identical processes running on different cores, in effect parallelising the catalogue fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up\n",
    "------------\n",
    "\n",
    "We'll use the setup from Example 3 to demonstrate how catalogue fitting works. First of all let's copy in the load_data function and generate the fit instructions dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import bagpipes as pipes\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "def load_goodss(ID):\n",
    "    \"\"\" Load CANDELS GOODS South photometry from the Guo et al. (2013) catalogue. \"\"\"\n",
    "\n",
    "    # load up the relevant columns from the catalogue.\n",
    "    cat = np.loadtxt(\"hlsp_candels_hst_wfc3_goodss-tot-multiband_f160w_v1-1photom_cat.txt\",\n",
    "                     usecols=(10, 13, 16, 19, 25, 28, 31, 34, 37, 43, 46, 49, 52, 55,\n",
    "                              11, 14, 17, 20, 26, 29, 32, 35, 38, 44, 47, 50, 53, 56))\n",
    "    \n",
    "    # Find the correct row for the object we want.\n",
    "    row = int(ID) - 1\n",
    "\n",
    "    # Extract the object we want from the catalogue.\n",
    "    fluxes = cat[row, :14]\n",
    "    fluxerrs = cat[row, 14:]\n",
    "\n",
    "    # Turn these into a 2D array.\n",
    "    photometry = np.c_[fluxes, fluxerrs]\n",
    "\n",
    "    # blow up the errors associated with any missing fluxes.\n",
    "    for i in range(len(photometry)):\n",
    "        if (photometry[i, 0] == 0.) or (photometry[i, 1] <= 0):\n",
    "            photometry[i,:] = [0., 9.9*10**99.]\n",
    "            \n",
    "    # Enforce a maximum SNR of 20, or 10 in the IRAC channels.\n",
    "    for i in range(len(photometry)):\n",
    "        if i < 10:\n",
    "            max_snr = 20.\n",
    "            \n",
    "        else:\n",
    "            max_snr = 10.\n",
    "        \n",
    "        if photometry[i, 0]/photometry[i, 1] > max_snr:\n",
    "            photometry[i, 1] = photometry[i, 0]/max_snr\n",
    "\n",
    "    return photometry\n",
    "\n",
    "goodss_filt_list = np.loadtxt(\"filters/goodss_filt_list.txt\", dtype=\"str\")\n",
    "\n",
    "\n",
    "exp = {}                                  \n",
    "exp[\"age\"] = (0.1, 15.)\n",
    "exp[\"tau\"] = (0.3, 10.)\n",
    "exp[\"massformed\"] = (1., 15.)\n",
    "exp[\"metallicity\"] = (0., 2.5)\n",
    "\n",
    "dust = {}\n",
    "dust[\"type\"] = \"Calzetti\"\n",
    "dust[\"Av\"] = (0., 2.)\n",
    "\n",
    "fit_instructions = {}\n",
    "fit_instructions[\"redshift\"] = (0., 10.)\n",
    "fit_instructions[\"exponential\"] = exp   \n",
    "fit_instructions[\"dust\"] = dust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic catalogue fitting\n",
    "--------------------------\n",
    "\n",
    "In the most basic case all you need is a list of IDs. You can pass this, along with fit_instructions and load_data, to fit_catalogue fit and then call the fit function in the same way as you would for the ordinary fit class. Let's start by fitting the first five objects in the Guo et al. catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bagpipes: fitting object 1\n",
      "\n",
      "\n",
      "Completed in 259.8 seconds.\n",
      "\n",
      "Parameter                          Posterior percentiles\n",
      "                                16th       50th       84th\n",
      "----------------------------------------------------------\n",
      "dust:Av                        0.850      0.997      1.201\n",
      "exponential:age                1.309      1.495      1.875\n",
      "exponential:massformed        10.628     10.692     10.759\n",
      "exponential:metallicity        0.643      1.522      2.139\n",
      "exponential:tau                0.318      0.370      0.493\n",
      "redshift                       0.473      0.504      0.527\n",
      "\n",
      "\n",
      "\n",
      "Bagpipes: fitting object 2\n",
      "\n",
      "\n",
      "Completed in 159.1 seconds.\n",
      "\n",
      "Parameter                          Posterior percentiles\n",
      "                                16th       50th       84th\n",
      "----------------------------------------------------------\n",
      "dust:Av                        0.149      0.314      0.494\n",
      "exponential:age                2.992      3.276      3.467\n",
      "exponential:massformed        10.267     10.369     10.446\n",
      "exponential:metallicity        2.260      2.409      2.475\n",
      "exponential:tau                1.193      1.619      3.334\n",
      "redshift                       1.762      1.853      1.915\n",
      "\n",
      "\n",
      "\n",
      "Bagpipes: fitting object 3\n",
      "\n",
      "\n",
      "Completed in 216.9 seconds.\n",
      "\n",
      "Parameter                          Posterior percentiles\n",
      "                                16th       50th       84th\n",
      "----------------------------------------------------------\n",
      "dust:Av                        0.522      0.616      0.690\n",
      "exponential:age                1.980      5.515      8.829\n",
      "exponential:massformed         9.138      9.498      9.676\n",
      "exponential:metallicity        0.173      0.317      0.768\n",
      "exponential:tau                0.622      2.768      6.013\n",
      "redshift                       0.212      0.257      0.303\n",
      "\n",
      "\n",
      "\n",
      "Bagpipes: fitting object 4\n",
      "\n",
      "\n",
      "Completed in 104.9 seconds.\n",
      "\n",
      "Parameter                          Posterior percentiles\n",
      "                                16th       50th       84th\n",
      "----------------------------------------------------------\n",
      "dust:Av                        1.168      1.382      1.612\n",
      "exponential:age                1.967      3.942      5.970\n",
      "exponential:massformed         9.197      9.389      9.595\n",
      "exponential:metallicity        0.278      0.715      1.617\n",
      "exponential:tau                2.536      5.595      8.586\n",
      "redshift                       0.564      0.662      0.797\n",
      "\n",
      "\n",
      "\n",
      "Bagpipes: fitting object 5\n",
      "\n",
      "\n",
      "Completed in 183.0 seconds.\n",
      "\n",
      "Parameter                          Posterior percentiles\n",
      "                                16th       50th       84th\n",
      "----------------------------------------------------------\n",
      "dust:Av                        0.036      0.114      0.243\n",
      "exponential:age                1.878      2.016      2.123\n",
      "exponential:massformed        10.625     10.671     10.714\n",
      "exponential:metallicity        2.177      2.373      2.465\n",
      "exponential:tau                0.500      0.559      0.646\n",
      "redshift                       2.905      3.000      3.066\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IDs = np.arange(1, 6)\n",
    "\n",
    "fit_cat = pipes.fit_catalogue(IDs, fit_instructions, load_goodss, spectrum_exists=False,\n",
    "                              cat_filt_list=goodss_filt_list, run=\"guo_cat\")\n",
    "\n",
    "fit_cat.fit(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real advantage here is that if you set another instance of these commands running elsewhere, Bagpipes will automatically share the objects in the catalogue out between these two (or more) processes. Processes can be started and stopped at any time and everything should carry on working.\n",
    "\n",
    "The only exception is starting more than one process at exactly the same time which can lead to conflicts. If you're setting a large number of parallel processes going at once, try adding a small random time delay to the beginning of the file to avoid this.\n",
    "\n",
    "\n",
    "## Merging fit_catalogue outputs\n",
    "\n",
    "A summary output catalogue will be generated in the pipes/cats directory automatically every time a process finishes fitting a batch of ten objects. To do this manually you can run the pipes.catalogue.merge command as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagpipes: 5 out of 5 objects completed.\n"
     ]
    }
   ],
   "source": [
    "pipes.catalogue.merge(\"guo_cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Cleaning partially completed objects\n",
    "    \n",
    "If the code crashes or is interruped in the middle of fitting an object, the code will see these objects as completed and not try to fit them again. To fix this, you can run the pipes.catalogue.clean command, specifying the run, which will kill all running processes and clear any partially completed objects so that they can be re-fitted from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagpipes: 5 out of 5 objects completed.\n",
      "Bagpipes: Partially completed objects reset.\n"
     ]
    }
   ],
   "source": [
    "pipes.catalogue.clean(\"guo_cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex options\n",
    "--------------------------\n",
    "\n",
    "There are a few other options that might come in handy. For example, if you have a list of spectroscopic redshifts for the objects you're fitting you might wish to fix the redshift of each fit to a different value. You can do this by passing an array of redshift values as the redshifts keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshifts = np.ones(ID.shape), \n",
    "\n",
    "cat_fit = pipes.catalogue_fit(IDs, fit_info, load_uvista, spectrum_exists=False,\n",
    "                              cat_filt_list=uvista_filt_list, run=\"guo_cat_redshift_1\",\n",
    "                              redshifts=redshifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead you want to vary the redshift within a small range around the input redshift you can pass a float to the redshift_sigma keyword argument. This will cause the redshift for each object to be fitted with a Gaussian prior centred on the value passed in redshifts with the specified standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying the filt_list\n",
    "\n",
    "Finally, if you have a bunch of different objects with different photometry that you want to fit with the same model you can pass a list of filter lists to catalogue_fit as the cat_filt_list keyword argument. If you do this you need to set the vary_filt_list keyword argument to True, and the code will expect the first entry in cat_filt_list to be the filter list for the first object and so on. We can set this up using the same filter list for each object just to demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_filt_lists = [uvista_filt_list] * 10\n",
    "\n",
    "cat_fit = pipes.catalogue_fit(IDs, fit_instructions, load_goodss, spectrum_exists=False,\n",
    "                              cat_filt_list=list_of_filt_lists, run=\"guo_cat_vary_filt_list\",\n",
    "                              redshifts=redshifts, redshift_sigma=0.05, vary_filt_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
