{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting catalogues of data with Bagpipes\n",
    "================================\n",
    "\n",
    "Commonly, we wish to fit a whole catalogue of observations of different objects (e.g. the Guo et al. (2013) [CANDELS GOODS South catalogue](https://archive.stsci.edu/prepds/candels) used in the previous examples). \n",
    "\n",
    "One approach would be to wrap the fitting commands from the previous three examples in a for loop, however Bagpipes provides a [catalogue fitting interface through the fit_catalogue class](https://bagpipes.readthedocs.io/en/latest/fitting_catalogues.html), which makes things easier. In addition, several options for MPI parallelisation are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up\n",
    "------------\n",
    "\n",
    "We'll use the setup from Example 3 to demonstrate how catalogue fitting works. First of all let's copy in the load_data function and generate the fit instructions dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import bagpipes as pipes\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "def load_goodss(ID):\n",
    "    \"\"\" Load CANDELS GOODS South photometry from the Guo et al. (2013) catalogue. \"\"\"\n",
    "\n",
    "    # load up the relevant columns from the catalogue.\n",
    "    cat = np.loadtxt(\"hlsp_candels_hst_wfc3_goodss-tot-multiband_f160w_v1-1photom_cat.txt\",\n",
    "                     usecols=(10, 13, 16, 19, 25, 28, 31, 34, 37, 40, 43, 46, 49, 52, 55,\n",
    "                              11, 14, 17, 20, 26, 29, 32, 35, 38, 41, 44, 47, 50, 53, 56))\n",
    "    \n",
    "    # Find the correct row for the object we want.\n",
    "    row = int(ID) - 1\n",
    "\n",
    "    # Extract the object we want from the catalogue.\n",
    "    fluxes = cat[row, :15]\n",
    "    fluxerrs = cat[row, 15:]\n",
    "\n",
    "    # Turn these into a 2D array.\n",
    "    photometry = np.c_[fluxes, fluxerrs]\n",
    "\n",
    "    # blow up the errors associated with any missing fluxes.\n",
    "    for i in range(len(photometry)):\n",
    "        if (photometry[i, 0] == 0.) or (photometry[i, 1] <= 0):\n",
    "            photometry[i,:] = [0., 9.9*10**99.]\n",
    "            \n",
    "    # Enforce a maximum SNR of 20, or 10 in the IRAC channels.\n",
    "    for i in range(len(photometry)):\n",
    "        if i < 10:\n",
    "            max_snr = 20.\n",
    "            \n",
    "        else:\n",
    "            max_snr = 10.\n",
    "        \n",
    "        if photometry[i, 0]/photometry[i, 1] > max_snr:\n",
    "            photometry[i, 1] = photometry[i, 0]/max_snr\n",
    "\n",
    "    return photometry\n",
    "\n",
    "goodss_filt_list = np.loadtxt(\"filters/goodss_filt_list.txt\", dtype=\"str\")\n",
    "\n",
    "\n",
    "exp = {}                                  \n",
    "exp[\"age\"] = (0.1, 15.)\n",
    "exp[\"tau\"] = (0.3, 10.)\n",
    "exp[\"massformed\"] = (1., 15.)\n",
    "exp[\"metallicity\"] = (0., 2.5)\n",
    "\n",
    "dust = {}\n",
    "dust[\"type\"] = \"Calzetti\"\n",
    "dust[\"Av\"] = (0., 2.)\n",
    "\n",
    "fit_instructions = {}\n",
    "fit_instructions[\"redshift\"] = (0., 10.)\n",
    "fit_instructions[\"exponential\"] = exp   \n",
    "fit_instructions[\"dust\"] = dust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic catalogue fitting\n",
    "--------------------------\n",
    "\n",
    "In the most basic case all you need is a list of IDs. You can pass this, along with fit_instructions and load_data, to fit_catalogue. Fitting is begun by calling the fit function in the same way as you would for the ordinary fit class. Let's start by fitting the first three objects in the Guo et al. catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bagpipes: fitting object 1\n",
      "\n",
      "\n",
      "Completed in 253.3 seconds.\n",
      "\n",
      "Parameter                          Posterior percentiles\n",
      "                                16th       50th       84th\n",
      "----------------------------------------------------------\n",
      "dust:Av                        0.846      0.999      1.205\n",
      "exponential:age                1.308      1.481      1.847\n",
      "exponential:massformed        10.626     10.689     10.756\n",
      "exponential:metallicity        0.678      1.535      2.127\n",
      "exponential:tau                0.318      0.366      0.479\n",
      "redshift                       0.474      0.504      0.527\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: It is strongly recommended that column names contain only upper and lower-case ASCII letters, digits, or underscores for maximum compatibility with other software (got '#ID'). [astropy.io.fits.column]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagpipes: 1 out of 3 objects completed.\n",
      "\n",
      "Bagpipes: fitting object 2\n",
      "\n",
      "\n",
      "Completed in 207.0 seconds.\n",
      "\n",
      "Parameter                          Posterior percentiles\n",
      "                                16th       50th       84th\n",
      "----------------------------------------------------------\n",
      "dust:Av                        0.148      0.319      0.506\n",
      "exponential:age                2.974      3.267      3.467\n",
      "exponential:massformed        10.263     10.366     10.441\n",
      "exponential:metallicity        2.256      2.407      2.475\n",
      "exponential:tau                1.180      1.656      3.618\n",
      "redshift                       1.762      1.850      1.918\n",
      "\n",
      "\n",
      "Bagpipes: 2 out of 3 objects completed.\n",
      "\n",
      "Bagpipes: fitting object 3\n",
      "\n",
      "\n",
      "Completed in 210.9 seconds.\n",
      "\n",
      "Parameter                          Posterior percentiles\n",
      "                                16th       50th       84th\n",
      "----------------------------------------------------------\n",
      "dust:Av                        0.519      0.616      0.685\n",
      "exponential:age                2.156      6.008      9.113\n",
      "exponential:massformed         9.173      9.510      9.688\n",
      "exponential:metallicity        0.173      0.319      0.737\n",
      "exponential:tau                0.693      3.097      6.198\n",
      "redshift                       0.212      0.256      0.304\n",
      "\n",
      "\n",
      "Bagpipes: 3 out of 3 objects completed.\n"
     ]
    }
   ],
   "source": [
    "IDs = np.arange(1, 4)\n",
    "\n",
    "fit_cat = pipes.fit_catalogue(IDs, fit_instructions, load_goodss, spectrum_exists=False,\n",
    "                              cat_filt_list=goodss_filt_list, run=\"guo_cat\")\n",
    "\n",
    "fit_cat.fit(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output catalogues\n",
    "\n",
    "A summary catalogue will automatically be saved under pipes/cats/run_name.fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex options\n",
    "--------------------------\n",
    "\n",
    "There are a few other options that might come in handy. For example, if you have a list of spectroscopic redshifts for the objects you're fitting you might wish to fix the redshift of each fit to a different value. You can do this by passing an array of redshift values as the redshifts keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshifts = np.ones(IDs.shape)\n",
    "\n",
    "cat_fit = pipes.fit_catalogue(IDs, fit_instructions, load_goodss, spectrum_exists=False,\n",
    "                              cat_filt_list=goodss_filt_list, run=\"guo_cat_redshift_1\",\n",
    "                              redshifts=redshifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead you want to vary the redshift within a small range around the input redshift you can additionally pass a float to the redshift_sigma keyword argument. This will cause the redshift for each object to be fitted with a Gaussian prior centred on the value passed in redshifts with the specified standard deviation. The maximum deviation allowed from the value in redshifts is three times the given redshift_sigma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying the filt_list\n",
    "\n",
    "Finally, if you have a bunch of different objects with different photometry that you want to fit with the same model you can pass a list of filter lists to catalogue_fit as the cat_filt_list keyword argument. If you do this you need to set the vary_filt_list keyword argument to True, and the code will expect the first entry in cat_filt_list to be the filter list for the first object and so on. We can set this up using the same filter list for each object just to demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_filt_lists = [goodss_filt_list] * 10\n",
    "\n",
    "cat_fit = pipes.fit_catalogue(IDs, fit_instructions, load_goodss, spectrum_exists=False,\n",
    "                              cat_filt_list=list_of_filt_lists, run=\"guo_cat_vary_filt_list\",\n",
    "                              redshifts=redshifts, redshift_sigma=0.05, vary_filt_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPI Parallelisation\n",
    "\n",
    "Fit_catalogue supports mpi parallelisation in the same way as fit (see Example 3). In addition it is also possible to request that fit_catalogue assigns a different object to each of the available cores, fitting multiple objects at once. This is faster for running on large numbers of cores or fitting simple models to large photometric catalogues, however the individual fits will take longer. This can be achieved by setting the mpi_serial keyword argument of fit_catalogue to True. [A slightly modified version of pymultinest](https://www.github.com/ACCarnall/pymultinest) is currently required to run bagpipes in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
